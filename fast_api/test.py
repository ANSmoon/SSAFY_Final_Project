print("[잘한 점 & 성과]\n\n프로젝트 초기부터 ERD 최종 점검, Jupyter lab 환경 세팅, 모델링 데이터셋 분류 등의 작업을 차근차근 진행하였다. 이를 통해 프로젝트의 기반을 탄탄히 다질 수 있었다. 또한 Hugging Face 모델을 활용하여 KoBART와 KoBERT 모델을 테스트하며 한글 지원 모델에 대한 이해를 높였다. 이후 AWS FM 모델, Titan v2.0, Claude 3.5 Sonnet 등 다양한 AI 모델을 적용하며 성능을 검토하고 최적화하는 작업을 수행하였다. \n\n특히 FAST API를 활용하여 개발일지 관련 API를 설계하고 구현하는 데 성공하였다. GPU 서버 설정, AWS 인증 처리 등 인프라 구축 작업도 원활히 진행하였다. 이를 통해 최종적으로 회고 추출 API와 회고 생성 API를 완성하였고, 모든 AI 기능을 구현할 수 있었다.\n\n전반적으로 개발 과정에서 다양한 기술 스택을 활용하고 체계적으로 문제를 해결해나가며 프로젝트를 성공적으로 완수할 수 있었다. 특히 FAST API, AWS 서비스, 병렬 처리 및 큐 시스템 등의 기술을 적용하여 안정적이고 효율적인 시스템을 구축하였다는 점에서 의의가 크다.\n\n[어려웠던 점 & 해결 과정]\n\n프로젝트 초기에는 긴 문장에 대한 정확도 및 분류 기준이 불분명하고, 여러 문장의 문맥 파악에 어려움이 있었다. 이를 해결하기 위해 대용량 NLP 모델 활용을 계획하고, FAST API 처리 및 API 연결 테스트를 진행하였다.\n\n또한 한글을 지원하는 모델이 부족하여 어려움을 겪었다. ChatGPT API 사용을 고려했지만 비용 문제가 발생하였고, 추출적 요약과 생성적 요약 모델 모두 fine-tuning이 필요했다. 이에 각 모델들의 fine-tuning을 진행하고 성능 평가를 수행하였다.\n\n개발 과정에서는 지역에 따른 서비스 불가능성, 모델의 쓰로틀링 문제, 인가 관련 설정 등 다양한 어려움이 있었다. 이를 해결하기 위해 개발일지 관련 자동화 로직을 구현하고, 사용자 피드백을 반영하는 등의 노력을 기울였다.\n\n특히 경험 추출 로직 및 키워드 설정 재설계, 복잡성 문제 해결 등 기술적 난제들이 많았다. 팀원들의 개발일지를 활용한 테스트와 프롬프트 질문 및 답변 형식 구성 등 다각도의 접근을 통해 이를 해결해나갔다.\n\n전반적으로 프로젝트 수행 과정에서 발생한 다양한 기술적 문제들을 체계적으로 분석하고 해결해나가는 과정이 쉽지 않았지만, 끈기 있게 대응하여 최종적으로 성공적인 결과를 도출할 수 있었다.\n\n[기술 스택 & 의사결정]\n\n이 프로젝트에서는 NLP 모델 개선을 위해 Hugging Face의 KoBART와 KoBERT 모델을 활용하였다. 한글 지원 모델이 부족한 상황에서 이들 모델은 성능 검토와 fine-tuning을 통해 유의미한 결과를 도출할 수 있었다.\n\n또한 AWS의 다양한 서비스를 적극 활용하였다. FM 모델, Titan v2.0, Claude 3.5 Sonnet 등 AI 모델을 적용하고, GPU 서버 설정, 인증 처리 등 인프라 구축에 AWS 서비스를 활용하였다. 이를 통해 안정적이고 확장 가능한 시스템을 구축할 수 있었다.\n\n특히 FAST API는 개발일지 관련 API 설계와 구현에 핵심적인 역할을 하였다. 단일 책임 원칙을 준수하며 API를 체계적으로 설계하고, Locust를 통한 트래픽 테스트로 성능을 최적화할 수 있었다.\n\n마지막으로 병렬 처리 및 큐 시스템을 활용하여 경험 추출 로직을 개선하고, 효율적인 키워드 매칭 시스템을 설계하였다. 이를 통해 복잡한 경험 추출 과정을 체계화하고 안정화할 수 있었다.\n\n전반적으로 이 프로젝트에서는 NLP, 클라우드 서비스, API 설계, 병렬 처리 등 다양한 기술 스택을 효과적으로 활용하여 안정적이고 확장 가능한 시스템을 구축할 수 있었다. 각 기술의 선택과 적용 과정은 프로젝트 성공의 핵심 요인이 되었다.")